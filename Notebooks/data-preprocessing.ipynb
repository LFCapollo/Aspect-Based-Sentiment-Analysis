{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import neuralcoref\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('../data/Restaurants_Train.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Restaurants_train.xml file\n",
    "The code below parses XML file and creates DataFrame with the following columns: ```Aspects, Terms, Text (review)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3044 reviews in this training set\n"
     ]
    }
   ],
   "source": [
    "labeled_reviews = []\n",
    "for sentence in root.findall(\"sentence\"):\n",
    "    entry = {}\n",
    "    aterms = []\n",
    "    aspects = []\n",
    "    if sentence.find(\"aspectTerms\"):\n",
    "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
    "            aterms.append(aterm.get(\"term\"))\n",
    "    if sentence.find(\"aspectCategories\"):\n",
    "        for aspect in sentence.find(\"aspectCategories\").findall(\"aspectCategory\"):\n",
    "            aspects.append(aspect.get(\"category\"))\n",
    "    entry[\"text\"], entry[\"terms\"], entry[\"aspects\"]= sentence[0].text, aterms, aspects\n",
    "    labeled_reviews.append(entry)\n",
    "\n",
    "labeled_df = pd.DataFrame(labeled_reviews)\n",
    "\n",
    "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "3  Where Gabriela personaly greets you and recomm...                     []   \n",
       "4  For those that go once and don't enjoy it, all...                     []   \n",
       "\n",
       "                           aspects  \n",
       "0                        [service]  \n",
       "1  [food, anecdotes/miscellaneous]  \n",
       "2                           [food]  \n",
       "3                        [service]  \n",
       "4        [anecdotes/miscellaneous]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save annotated reviews\n",
    "labeled_df.to_pickle(\"../pickled_files/annotated_reviews_df.pkl\")\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Co-referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "# Define function for replacing pronouns using neuralcoref\n",
    "def replace_pronouns(text):\n",
    "    doc = nlp(text)\n",
    "    return doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I drove Joe home because Joe lives near my apartment.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_coreferencing = replace_pronouns(\"I drove Joe home because he lives near my apartment.\")\n",
    "example_coreferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "\n",
       "                           aspects  \n",
       "0                        [service]  \n",
       "1  [food, anecdotes/miscellaneous]  \n",
       "2                           [food]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read annotated reviews DataFrame\n",
    "\n",
    "annotated_reviews_df = pd.read_pickle(\"../pickled_files/annotated_reviews_df.pkl\")\n",
    "annotated_reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The code below fixes co-referencing in reviews and creates new column \"fixed_review\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with fixed co-referencing\n",
    "\n",
    "annotated_reviews_df[\"fixed_review\"] = annotated_reviews_df[\"text\"].map(lambda x: replace_pronouns(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love play football .\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize_sentence(\"I love playing football.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize Sentence and fix output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_reviews_df[\"fixed_review\"] = annotated_reviews_df[\"text\"].map(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes spaces before punctuations\n",
    "# removes spaces between separated words do n't returns don't\n",
    "\n",
    "def fix_output(text):\n",
    "    text = text.replace(\" n't\", \"n't\")\n",
    "    return re.sub(r'\\s([,?.!\"](?:\\s|$))', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_reviews_df[\"fixed_review\"] = annotated_reviews_df[\"fixed_review\"].apply(remove_punct_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "      <th>fixed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>But the staff be so horrible to us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>The food be uniformly exceptional, with a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "3  Where Gabriela personaly greets you and recomm...                     []   \n",
       "4  For those that go once and don't enjoy it, all...                     []   \n",
       "\n",
       "                           aspects  \\\n",
       "0                        [service]   \n",
       "1  [food, anecdotes/miscellaneous]   \n",
       "2                           [food]   \n",
       "3                        [service]   \n",
       "4        [anecdotes/miscellaneous]   \n",
       "\n",
       "                                        fixed_review  \n",
       "0                But the staff be so horrible to us.  \n",
       "1  To be completely fair, the only redeeming fact...  \n",
       "2  The food be uniformly exceptional, with a very...  \n",
       "3  Where Gabriela personaly greets you and recomm...  \n",
       "4  For those that go once and don't enjoy it, all...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "      <th>fixed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>But the staff be so horrible to us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>The food be uniformly exceptional, with a very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "\n",
       "                           aspects  \\\n",
       "0                        [service]   \n",
       "1  [food, anecdotes/miscellaneous]   \n",
       "2                           [food]   \n",
       "\n",
       "                                        fixed_review  \n",
       "0                But the staff be so horrible to us.  \n",
       "1  To be completely fair, the only redeeming fact...  \n",
       "2  The food be uniformly exceptional, with a very...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_reviews_df.to_pickle(\"../pickled_files/annotated_reviews_df2.pkl\")\n",
    "\n",
    "# Read pickled file with replaced pronouns\n",
    "\n",
    "annotated_reviews_df = pd.read_pickle(\"../pickled_files/annotated_reviews_df2.pkl\")\n",
    "annotated_reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below transforms \"aspects\" which are categorical into vectors for model training.\n",
    "\n",
    "The data-set is split into training set and test set 75%, 25% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabelBinarizer transforms aspects into arrays\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(annotated_reviews_df[\"aspects\"])\n",
    "X = annotated_reviews_df[\"fixed_review\"]\n",
    "\n",
    "\n",
    "# Split data into train and test set 75% 25%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving training sets and test sets as pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../pickled_files/mlb.pkl'\n",
    "pickle.dump(mlb, open(filename, 'wb'))\n",
    "X_train.to_pickle(\"../pickled_files/X_train.pkl\")\n",
    "X_test.to_pickle(\"../pickled_files/X_test.pkl\")\n",
    "\n",
    "filename = '../pickled_files/y_train.pkl'\n",
    "pickle.dump(y_train, open(filename, 'wb'))\n",
    "filename = '../pickled_files/y_test.pkl'\n",
    "pickle.dump(y_test, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train best model (Multinomial Naive Bayes) using full data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Best model (Multinomial Naive Bayes) using full data-set\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-2))),])\n",
    "\n",
    "text_clf = text_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../pickled_files/NB_model.pkl'\n",
    "pickle.dump(text_clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}